{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marek-bardonski/airev-advanced-workshops/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn_KXjFSemkG",
        "colab_type": "code",
        "outputId": "f2220dfc-a9a8-442c-cf6b-42cc52d672df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# AI REV LLC - Copyrights 2020\n",
        "# [Google Colab] Change runtime mode to GPU\n",
        "# https://docs.rapids.ai/\n",
        "# https://alraqmiyyat.github.io/2013/01-02.html\n",
        "\n",
        "!nvcc --version\n",
        "!pip3 install wget\n",
        "\n",
        "# https://github.com/rapidsai/cudf/issues/3390\n",
        "!pip3 install pyarrow==0.15.0 ## Workaround to cover up for Google Colab bug\n",
        "\n",
        "#!pip3 install cudf-cuda100\n",
        "#!pip3 install nvstrings-cuda100\n",
        "#!pip3 install cuml-cuda100\n",
        "#!pip3 install nvvm-cuda100\n",
        "\n",
        "# RAPIDS installation script. Thanks Ritchie Ng and NVIDIA Corporation.\n",
        "# install miniconda\n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local\n",
        "\n",
        "# install RAPIDS packages\n",
        "!conda install -q -y --prefix /usr/local -c conda-forge \\\n",
        "  -c rapidsai-nightly/label/cuda10.0 -c nvidia/label/cuda10.0 \\\n",
        "  cudf cuml"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=ec77d2864e07685dabb2076e01a156fe07e67627874d72deb9173ef67cae155a\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Installing collected packages: pyarrow\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "Successfully installed pyarrow-0.15.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyarrow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "--2020-01-04 11:29:48--  https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c94f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58468498 (56M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-4.5.4-Linux-x86_64.sh’\n",
            "\n",
            "\r          Miniconda   0%[                    ]       0  --.-KB/s               \r         Miniconda3  60%[===========>        ]  33.75M   169MB/s               \rMiniconda3-4.5.4-Li 100%[===================>]  55.76M   165MB/s    in 0.3s    \n",
            "\n",
            "2020-01-04 11:29:49 (165 MB/s) - ‘Miniconda3-4.5.4-Linux-x86_64.sh’ saved [58468498/58468498]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "installing: python-3.6.5-hc3d631a_2 ...\n",
            "Python 3.6.5 :: Anaconda, Inc.\n",
            "installing: ca-certificates-2018.03.07-0 ...\n",
            "installing: conda-env-2.6.0-h36134e3_1 ...\n",
            "installing: libgcc-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libstdcxx-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libffi-3.2.1-hd88cf55_4 ...\n",
            "installing: ncurses-6.1-hf484d3e_0 ...\n",
            "installing: openssl-1.0.2o-h20670df_0 ...\n",
            "installing: tk-8.6.7-hc745277_3 ...\n",
            "installing: xz-5.2.4-h14c3975_4 ...\n",
            "installing: yaml-0.1.7-had09818_2 ...\n",
            "installing: zlib-1.2.11-ha838bed_2 ...\n",
            "installing: libedit-3.1.20170329-h6b74fdf_2 ...\n",
            "installing: readline-7.0-ha6073c6_4 ...\n",
            "installing: sqlite-3.23.1-he433501_0 ...\n",
            "installing: asn1crypto-0.24.0-py36_0 ...\n",
            "installing: certifi-2018.4.16-py36_0 ...\n",
            "installing: chardet-3.0.4-py36h0f667ec_1 ...\n",
            "installing: idna-2.6-py36h82fb2a8_1 ...\n",
            "installing: pycosat-0.6.3-py36h0a5515d_0 ...\n",
            "installing: pycparser-2.18-py36hf9f622e_1 ...\n",
            "installing: pysocks-1.6.8-py36_0 ...\n",
            "installing: ruamel_yaml-0.15.37-py36h14c3975_2 ...\n",
            "installing: six-1.11.0-py36h372c433_1 ...\n",
            "installing: cffi-1.11.5-py36h9745a5d_0 ...\n",
            "installing: setuptools-39.2.0-py36_0 ...\n",
            "installing: cryptography-2.2.2-py36h14c3975_0 ...\n",
            "installing: wheel-0.31.1-py36_0 ...\n",
            "installing: pip-10.0.1-py36_0 ...\n",
            "installing: pyopenssl-18.0.0-py36_0 ...\n",
            "installing: urllib3-1.22-py36hbe7ace6_0 ...\n",
            "installing: requests-2.18.4-py36he2e5f8d_1 ...\n",
            "installing: conda-4.5.4-py36_0 ...\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs: \n",
            "    - cudf\n",
            "    - cuml\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    librmm-0.11.0b191205       |      cuda10.0_72          52 KB  rapidsai-nightly/label/cuda10.0\n",
            "    cudnn-7.6.4                |       cuda10.0_0       226.6 MB\n",
            "    pytz-2019.3                |             py_0         237 KB  conda-forge\n",
            "    libopenblas-0.3.7          |       h5ec1e0e_6         7.6 MB  conda-forge\n",
            "    pip-19.3.1                 |           py37_0         1.9 MB  conda-forge\n",
            "    libcblas-3.8.0             |      14_openblas          10 KB  conda-forge\n",
            "    grpc-cpp-1.23.0            |       h18db393_0         4.5 MB  conda-forge\n",
            "    numba-0.46.0               |   py37hb3f55d8_1         3.2 MB  conda-forge\n",
            "    cudatoolkit-10.0.130       |                0       380.0 MB\n",
            "    arrow-cpp-0.15.0           |   py37h090bef1_2        18.1 MB  conda-forge\n",
            "    bzip2-1.0.8                |       h516909a_2         396 KB  conda-forge\n",
            "    libllvm8-8.0.1             |       hc9558a2_0        23.2 MB  conda-forge\n",
            "    fastavro-0.22.9            |   py37h516909a_0         411 KB  conda-forge\n",
            "    libgcc-ng-9.2.0            |       hdf63c60_0         8.6 MB  conda-forge\n",
            "    re2-2020.01.01             |       he1b5a44_0         422 KB  conda-forge\n",
            "    boost-cpp-1.70.0           |       h8e57a91_2        21.1 MB  conda-forge\n",
            "    libevent-2.1.10            |       h72c5cf5_0         1.3 MB  conda-forge\n",
            "    readline-8.0               |       hf8c457e_0         441 KB  conda-forge\n",
            "    libgfortran-ng-7.3.0       |       hdf63c60_2         1.7 MB  conda-forge\n",
            "    six-1.13.0                 |           py37_0          22 KB  conda-forge\n",
            "    c-ares-1.15.0              |    h516909a_1001         100 KB  conda-forge\n",
            "    python-dateutil-2.8.1      |             py_0         220 KB  conda-forge\n",
            "    sqlite-3.30.1              |       hcee41ef_0         2.0 MB  conda-forge\n",
            "    _libgcc_mutex-0.1          |             main           2 KB  conda-forge\n",
            "    ca-certificates-2019.11.28 |       hecc5488_0         145 KB  conda-forge\n",
            "    ld_impl_linux-64-2.33.1    |       h53a641e_7         653 KB  conda-forge\n",
            "    zstd-1.4.3                 |       h3b9ef0a_0         935 KB  conda-forge\n",
            "    thrift-cpp-0.12.0          |    hf3afdfd_1004         2.4 MB  conda-forge\n",
            "    setuptools-44.0.0          |           py37_0         659 KB  conda-forge\n",
            "    python-3.7.6               |       h357f687_1        52.9 MB  conda-forge\n",
            "    rmm-0.11.0b191205          |          py37_72         281 KB  rapidsai-nightly/label/cuda10.0\n",
            "    libprotobuf-3.8.0          |       h8b12597_0         4.7 MB  conda-forge\n",
            "    pandas-0.24.2              |   py37hb3f55d8_1        11.1 MB  conda-forge\n",
            "    llvmlite-0.30.0            |   py37h8b12597_1         325 KB  conda-forge\n",
            "    ncurses-6.1                |    hf484d3e_1002         1.3 MB  conda-forge\n",
            "    snappy-1.1.7               |    he1b5a44_1003          39 KB  conda-forge\n",
            "    zlib-1.2.11                |    h516909a_1006         105 KB  conda-forge\n",
            "    cuml-0.11.0a1191204        |cuda10.0_py37_1141         8.4 MB  rapidsai-nightly/label/cuda10.0\n",
            "    icu-64.2                   |       he1b5a44_1        12.6 MB  conda-forge\n",
            "    dlpack-0.2                 |       he1b5a44_1          13 KB  conda-forge\n",
            "    openssl-1.1.1d             |       h516909a_0         2.1 MB  conda-forge\n",
            "    fastrlock-0.4              |py37he1b5a44_1000          31 KB  conda-forge\n",
            "    libnvstrings-0.11.0a191205 |    cuda10.0_3934        29.6 MB  rapidsai-nightly/label/cuda10.0\n",
            "    liblapack-3.8.0            |      14_openblas          10 KB  conda-forge\n",
            "    gflags-2.2.2               |    he1b5a44_1002         175 KB  conda-forge\n",
            "    xz-5.2.4                   |    h14c3975_1001         366 KB  conda-forge\n",
            "    certifi-2019.11.28         |           py37_0         148 KB  conda-forge\n",
            "    tk-8.6.10                  |       hed695b0_0         3.2 MB  conda-forge\n",
            "    libstdcxx-ng-9.2.0         |       hdf63c60_0         4.5 MB  conda-forge\n",
            "    libcumlprims-0.11.0a191210 |     cuda10.0_127         5.6 MB  rapidsai-nightly/label/cuda10.0\n",
            "    parquet-cpp-1.5.1          |                2           3 KB  conda-forge\n",
            "    libcuml-0.11.0a1191204     |    cuda10.0_1141        48.2 MB  rapidsai-nightly/label/cuda10.0\n",
            "    double-conversion-3.1.5    |       he1b5a44_2          85 KB  conda-forge\n",
            "    uriparser-0.9.3            |       he1b5a44_1          49 KB  conda-forge\n",
            "    libffi-3.2.1               |    he1b5a44_1006          46 KB  conda-forge\n",
            "    nvstrings-0.11.0a191205    |        py37_3934         128 KB  rapidsai-nightly/label/cuda10.0\n",
            "    libcudf-0.11.0a191205      |    cuda10.0_3934        62.7 MB  rapidsai-nightly/label/cuda10.0\n",
            "    libblas-3.8.0              |      14_openblas          10 KB  conda-forge\n",
            "    brotli-1.0.7               |    he1b5a44_1000         1.0 MB  conda-forge\n",
            "    wheel-0.33.6               |           py37_0          35 KB  conda-forge\n",
            "    cudf-0.11.0a191205         |        py37_3934         7.9 MB  rapidsai-nightly/label/cuda10.0\n",
            "    lz4-c-1.8.3                |    he1b5a44_1001         187 KB  conda-forge\n",
            "    nccl-2.4.8.1               |       hd6f8bf8_1       136.5 MB  conda-forge\n",
            "    glog-0.4.0                 |       he1b5a44_1         104 KB  conda-forge\n",
            "    cupy-6.6.0                 |   py37h809cb0f_1        14.6 MB  conda-forge\n",
            "    fsspec-0.6.2               |             py_0          46 KB  conda-forge\n",
            "    pyarrow-0.15.0             |   py37h8b68381_1         3.2 MB  conda-forge\n",
            "    numpy-1.17.3               |   py37h95a1406_0         5.1 MB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        1.10 GB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "    _libgcc_mutex:     0.1-main                          conda-forge                    \n",
            "    arrow-cpp:         0.15.0-py37h090bef1_2             conda-forge                    \n",
            "    boost-cpp:         1.70.0-h8e57a91_2                 conda-forge                    \n",
            "    brotli:            1.0.7-he1b5a44_1000               conda-forge                    \n",
            "    bzip2:             1.0.8-h516909a_2                  conda-forge                    \n",
            "    c-ares:            1.15.0-h516909a_1001              conda-forge                    \n",
            "    cudatoolkit:       10.0.130-0                                                       \n",
            "    cudf:              0.11.0a191205-py37_3934           rapidsai-nightly/label/cuda10.0\n",
            "    cudnn:             7.6.4-cuda10.0_0                                                 \n",
            "    cuml:              0.11.0a1191204-cuda10.0_py37_1141 rapidsai-nightly/label/cuda10.0\n",
            "    cupy:              6.6.0-py37h809cb0f_1              conda-forge                    \n",
            "    dlpack:            0.2-he1b5a44_1                    conda-forge                    \n",
            "    double-conversion: 3.1.5-he1b5a44_2                  conda-forge                    \n",
            "    fastavro:          0.22.9-py37h516909a_0             conda-forge                    \n",
            "    fastrlock:         0.4-py37he1b5a44_1000             conda-forge                    \n",
            "    fsspec:            0.6.2-py_0                        conda-forge                    \n",
            "    gflags:            2.2.2-he1b5a44_1002               conda-forge                    \n",
            "    glog:              0.4.0-he1b5a44_1                  conda-forge                    \n",
            "    grpc-cpp:          1.23.0-h18db393_0                 conda-forge                    \n",
            "    icu:               64.2-he1b5a44_1                   conda-forge                    \n",
            "    ld_impl_linux-64:  2.33.1-h53a641e_7                 conda-forge                    \n",
            "    libblas:           3.8.0-14_openblas                 conda-forge                    \n",
            "    libcblas:          3.8.0-14_openblas                 conda-forge                    \n",
            "    libcudf:           0.11.0a191205-cuda10.0_3934       rapidsai-nightly/label/cuda10.0\n",
            "    libcuml:           0.11.0a1191204-cuda10.0_1141      rapidsai-nightly/label/cuda10.0\n",
            "    libcumlprims:      0.11.0a191210-cuda10.0_127        rapidsai-nightly/label/cuda10.0\n",
            "    libevent:          2.1.10-h72c5cf5_0                 conda-forge                    \n",
            "    libgfortran-ng:    7.3.0-hdf63c60_2                  conda-forge                    \n",
            "    liblapack:         3.8.0-14_openblas                 conda-forge                    \n",
            "    libllvm8:          8.0.1-hc9558a2_0                  conda-forge                    \n",
            "    libnvstrings:      0.11.0a191205-cuda10.0_3934       rapidsai-nightly/label/cuda10.0\n",
            "    libopenblas:       0.3.7-h5ec1e0e_6                  conda-forge                    \n",
            "    libprotobuf:       3.8.0-h8b12597_0                  conda-forge                    \n",
            "    librmm:            0.11.0b191205-cuda10.0_72         rapidsai-nightly/label/cuda10.0\n",
            "    llvmlite:          0.30.0-py37h8b12597_1             conda-forge                    \n",
            "    lz4-c:             1.8.3-he1b5a44_1001               conda-forge                    \n",
            "    nccl:              2.4.8.1-hd6f8bf8_1                conda-forge                    \n",
            "    numba:             0.46.0-py37hb3f55d8_1             conda-forge                    \n",
            "    numpy:             1.17.3-py37h95a1406_0             conda-forge                    \n",
            "    nvstrings:         0.11.0a191205-py37_3934           rapidsai-nightly/label/cuda10.0\n",
            "    pandas:            0.24.2-py37hb3f55d8_1             conda-forge                    \n",
            "    parquet-cpp:       1.5.1-2                           conda-forge                    \n",
            "    pyarrow:           0.15.0-py37h8b68381_1             conda-forge                    \n",
            "    python-dateutil:   2.8.1-py_0                        conda-forge                    \n",
            "    pytz:              2019.3-py_0                       conda-forge                    \n",
            "    re2:               2020.01.01-he1b5a44_0             conda-forge                    \n",
            "    rmm:               0.11.0b191205-py37_72             rapidsai-nightly/label/cuda10.0\n",
            "    snappy:            1.1.7-he1b5a44_1003               conda-forge                    \n",
            "    thrift-cpp:        0.12.0-hf3afdfd_1004              conda-forge                    \n",
            "    uriparser:         0.9.3-he1b5a44_1                  conda-forge                    \n",
            "    zstd:              1.4.3-h3b9ef0a_0                  conda-forge                    \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "    ca-certificates:   2018.03.07-0                                                      --> 2019.11.28-hecc5488_0 conda-forge\n",
            "    certifi:           2018.4.16-py36_0                                                  --> 2019.11.28-py37_0     conda-forge\n",
            "    libffi:            3.2.1-hd88cf55_4                                                  --> 3.2.1-he1b5a44_1006   conda-forge\n",
            "    libgcc-ng:         7.2.0-hdf63c60_3                                                  --> 9.2.0-hdf63c60_0      conda-forge\n",
            "    libstdcxx-ng:      7.2.0-hdf63c60_3                                                  --> 9.2.0-hdf63c60_0      conda-forge\n",
            "    ncurses:           6.1-hf484d3e_0                                                    --> 6.1-hf484d3e_1002     conda-forge\n",
            "    openssl:           1.0.2o-h20670df_0                                                 --> 1.1.1d-h516909a_0     conda-forge\n",
            "    pip:               10.0.1-py36_0                                                     --> 19.3.1-py37_0         conda-forge\n",
            "    python:            3.6.5-hc3d631a_2                                                  --> 3.7.6-h357f687_1      conda-forge\n",
            "    readline:          7.0-ha6073c6_4                                                    --> 8.0-hf8c457e_0        conda-forge\n",
            "    setuptools:        39.2.0-py36_0                                                     --> 44.0.0-py37_0         conda-forge\n",
            "    six:               1.11.0-py36h372c433_1                                             --> 1.13.0-py37_0         conda-forge\n",
            "    sqlite:            3.23.1-he433501_0                                                 --> 3.30.1-hcee41ef_0     conda-forge\n",
            "    tk:                8.6.7-hc745277_3                                                  --> 8.6.10-hed695b0_0     conda-forge\n",
            "    wheel:             0.31.1-py36_0                                                     --> 0.33.6-py37_0         conda-forge\n",
            "    xz:                5.2.4-h14c3975_4                                                  --> 5.2.4-h14c3975_1001   conda-forge\n",
            "    zlib:              1.2.11-ha838bed_2                                                 --> 1.2.11-h516909a_1006  conda-forge\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_feLB_gSiQo4",
        "colab_type": "text"
      },
      "source": [
        "**Remember to restart the runtime at this moment and restart the procedure from the top.** \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET1uPRNm4TSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set environment vars\n",
        "import sys, os, shutil\n",
        "\n",
        "sys.path.append('/usr/local/lib/python3.6/site-packages/')\n",
        "sys.path.append('/usr/local/')\n",
        "os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'\n",
        "\n",
        "# copy .so files to current working dir\n",
        "for fn in ['libcudf.so', 'librmm.so']:\n",
        "  shutil.copy('/usr/local/lib/'+fn, os.getcwd())\n",
        "\n",
        "import wget\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "import cudf\n",
        "import sys, os\n",
        "import nvcategory\n",
        "import os\n",
        "import numpy as np\n",
        "import nvstrings\n",
        "import nltk\n",
        "from numba import cuda\n",
        "import json\n",
        "import nvtext\n",
        "import ctypes\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import cupy\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOFllMJm9Pe_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmPAza7yBe5z",
        "colab_type": "text"
      },
      "source": [
        "**If you got import errors, please look above or ask instructor.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBx-VbqMYEBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Raw datasets are samples from WebHose.io \n",
        "print('Beginning dataset download with wget module')\n",
        "\n",
        "url = 'https://bardonski.pl/chineese.zip'\n",
        "wget.download(url)\n",
        "url = 'https://bardonski.pl/arabic.zip'\n",
        "wget.download(url)\n",
        "url = 'https://bardonski.pl/arabic-true-pr.csv'\n",
        "wget.download(url)\n",
        "\n",
        "print('Beginning word vectors download with wget module')\n",
        "url = 'https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ar.300.vec.gz'\n",
        "print('Word vectors unzip')\n",
        "wget.download(url)\n",
        "!gzip -d cc.ar.300.vec.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDlFmOkAKDBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zip = ZipFile('chineese.zip')\n",
        "zip.extractall()\n",
        "\n",
        "!mkdir chineese\n",
        "\n",
        "zip = ZipFile('630_webhose-2016-10_20170904084325.zip')\n",
        "zip.extractall('chineese')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G37zDeifXwLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zip = ZipFile('arabic.zip')\n",
        "zip.extractall()\n",
        "\n",
        "!mkdir arabic\n",
        "\n",
        "zip = ZipFile('627_webhose-2016-10_20170904083346.zip')\n",
        "zip.extractall('arabic')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLyn-jT-Y3JY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Expected 236384 arabic articles\n",
        "#Expected 316004 chineese articles\n",
        "!ls arabic -l | wc -l\n",
        "!ls chineese -l | wc -l\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjkkjECXGYsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbriaZfeaKr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Thanks VibhuJawa\n",
        "def get_text(lines):\n",
        "    \"\"\"\n",
        "        returns non empty lines from a list of lines\n",
        "    \"\"\"\n",
        "    decoded = json.loads(lines[0])\n",
        "    clean_lines = decoded['text']\n",
        "    return [clean_lines]\n",
        "\n",
        "def get_txt_lines(data_dir):\n",
        "    \"\"\"\n",
        "        Read text lines from gutenberg tests\n",
        "        returns (text_ls,fname_ls) where \n",
        "        text_ls = input_text_lines and fname_ls = list of file names\n",
        "    \"\"\"\n",
        "    text_ls = []\n",
        "    fname_ls = []\n",
        "    for fn in os.listdir(data_dir):\n",
        "        full_fn = os.path.join(data_dir,fn)\n",
        "        with open(full_fn,encoding=\"utf-8\",errors=\"ignore\") as f:\n",
        "            content = f.readlines()\n",
        "            content = get_text(content)\n",
        "            if content is not None:\n",
        "                text_ls += content\n",
        "                ### dont add .txt to the file\n",
        "                fname_ls += [fn[:-4]]*len(content)\n",
        "        #return text_ls, fname_ls    \n",
        "    \n",
        "    return text_ls, fname_ls    \n",
        "    \n",
        "print(\"File Read Time:\")\n",
        "%time txt_ls,fname_ls = get_txt_lines('arabic')\n",
        "df = cudf.DataFrame()\n",
        "\n",
        "print(\"\\nCUDF  Creation Time:\")\n",
        "%time df['text'] = nvstrings.to_device(txt_ls)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBIamb5gbd_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Number of lines in the DF = {:,}\".format(len(df)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fheBQLXhr-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head(10).to_pandas()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEaGqGwcy6Au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STOPWORDS = nltk.corpus.stopwords.words('arabic')\n",
        "\n",
        "filters = [ '!', '\"', '#', '$', '%', '&', '(', ')', '*', '+', '-', '.', '/',  '\\\\', ':', ';', '<', '=', '>',\n",
        "           '?', '@', '[', ']', '^', '_', '`', '{', '|', '}', '\\~', '\\t','\\\\n',\"'\",\",\",'~' , '—']\n",
        "\n",
        "def preprocess_text(input_strs , filters=None , stopwords=STOPWORDS):\n",
        "    \"\"\"\n",
        "        * filter punctuation\n",
        "        * to_lower\n",
        "        * remove stop words (from nltk corpus)\n",
        "        * remove multiple spaces with one\n",
        "        * remove leading spaces    \n",
        "    \"\"\"\n",
        "    \n",
        "    # filter punctuation and case conversion\n",
        "    input_strs = input_strs.str.replace_multi(filters, ' ', regex=False)\n",
        "    input_strs = input_strs.str.lower()\n",
        "        \n",
        "    # remove stopwords\n",
        "    stopwords_gpu = nvstrings.to_device(stopwords)\n",
        "    input_strs = nvtext.replace_tokens(input_strs.data, stopwords_gpu, ' ')\n",
        "    input_strs = cudf.Series(input_strs)\n",
        "        \n",
        "    # replace multiple spaces with single one and strip leading/trailing spaces\n",
        "    input_strs = input_strs.str.replace(r\"\\s+\", ' ', regex=True)\n",
        "    input_strs = input_strs.str.strip(' ')\n",
        "    \n",
        "    return input_strs\n",
        "\n",
        "def preprocess_text_df(df, text_cols=['text'], **kwargs):\n",
        "    for col in text_cols:\n",
        "        df[col] = preprocess_text(df[col], **kwargs)\n",
        "    return  df\n",
        "\n",
        "%time df = preprocess_text_df(df, filters=filters)\n",
        "\n",
        "# TASK #1 - Remove stopwords keeping the arabic symbols. Hint: ^[\\u0621-\\u064A0-9 ]+$\n",
        "# TASK #2 - Shuffle the DataFrame df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FNhnzVazYi_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head(5).to_pandas()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oBSnlWUz2o3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SAMPLE_SIZE = 1000\n",
        "df2 = df.head(SAMPLE_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w64RIm__DRRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2.to_pandas()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHgMOTlfDSsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How many articles contain the word bitcoin?\n",
        "sum(df2['text'].str.find('بيتكوين')) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrjDHohlZxdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_df = cudf.read_csv(\"cc.ar.300.vec\",\n",
        "                       header=None,\n",
        "                       delim_whitespace=True,\n",
        "                       quoting=3,\n",
        "                       skiprows=1)  #ignore quoting\n",
        "print(pre_df.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRoYzXaB521k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the file with cudf\n",
        "names = ['query', 'title', 'text', 'link', 'desc','other']\n",
        "# Note 'int' for 3rd column- text will be hashed\n",
        "dtypes = ['str', 'str', 'str', 'str', 'str', 'str']\n",
        "df_pos = cudf.read_csv('arabic-true-pr.csv', delimiter=',',\n",
        "                   names=names, dtype=dtypes,\n",
        "                   skiprows=1)\n",
        "df_pos.head(15).to_pandas()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o-PIM-H6bNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_pos = df_pos.drop(['query', 'title', 'link', 'desc', 'other'])\n",
        "df_pos.add_column('target', 1)\n",
        "df_pos = df_pos.dropna()\n",
        "df2.add_column('target', 0)\n",
        "df2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4r04jGBfK9G_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = cudf.core.reshape.concat([df_pos, df2], 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8YAeHzg701a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Thanks Ayush Kumar\n",
        "# setting the max length of each article to 200\n",
        "MAX_LEN = 200\n",
        "num_sents = df['text'].data.size()\n",
        "\n",
        "# generate the tokens\n",
        "seq = df['text'].data.split_record(' ')\n",
        "# padding each strings if smaller or trim down if larger\n",
        "for i in range(len(seq)):\n",
        "  l = seq[i].size()\n",
        "  if l<= MAX_LEN:\n",
        "    seq[i] = seq[i].add_strings(nvstrings.to_device((MAX_LEN-l)*['PAD']))\n",
        "  else:\n",
        "    seq[i] = seq[i].remove_strings(list(range(MAX_LEN,l)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR4_RAaLN1uI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(seq[40])\n",
        "print(seq[4])\n",
        "print((len(seq)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T54I5yyN_kD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generating the indices corresponding each token \n",
        "c = nvcategory.from_strings_list(seq)\n",
        "print(c.keys_size())   # total number of unique tokens\n",
        "print(c.size())       # total number of tokens or vocabulary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi4M5jLJPHPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating gdf using unique tokens\n",
        "# TASK more preprocessing - that can be tricky in Arabic\n",
        "sent_df = cudf.DataFrame({'tokens':c.keys()})\n",
        "sent_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5vOj868PNk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preparing the X_train \n",
        "X_train = cuda.device_array((num_sents, MAX_LEN), dtype=np.int32)\n",
        "c.values(X_train.device_ctypes_pointer.value)\n",
        "print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU1jkxGZYubM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preparing the y_train\n",
        "y_train = df['target'].astype('float32').to_gpu_array()\n",
        "print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxYdgJU1Qj7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating embedding matrix \n",
        "vocab_df = sent_df.merge(pre_df,\n",
        "                         left_on='tokens',\n",
        "                         right_on='0',\n",
        "                         how='left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlerzfKbQ1M_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_token = vocab_df.shape[0]\n",
        "print(all_token)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L448hiT39uDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_df.drop_column('0')\n",
        "vocab_df.drop_column('tokens')\n",
        "\n",
        "# filling the not found tokens with random vector\n",
        "for c in vocab_df.columns:\n",
        "  vocab_df[c] = vocab_df[c].fillna(cupy.random.normal(size=all_token)).astype(np.float32)\n",
        "\n",
        "# embedding matrix\n",
        "vocab = vocab_df.as_gpu_matrix(order='C')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOQqgbLD-Fwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# open issue #23067\n",
        "def devndarray2tensor(dev_arr, dtyp='float32'):\n",
        "    dmap = {'float32':torch.float32, 'int32':torch.int32}\n",
        "    t = torch.empty(size=dev_arr.shape, dtype=dmap[dtyp]).cuda()\n",
        "    ctx = cuda.cudadrv.driver.driver.get_context()\n",
        "    \n",
        "    # constant value of #bytes in float32 = 4\n",
        "    mp = cuda.cudadrv.driver.MemoryPointer(ctx, ctypes.c_ulong(t.data_ptr()), t.numel()*4)\n",
        "    tmp_arr = cuda.cudadrv.devicearray.DeviceNDArray(t.size(), [i*4 for i in t.stride()], np.dtype(dtyp), \n",
        "                                            gpu_data=mp, stream=torch.cuda.current_stream().cuda_stream)\n",
        "    tmp_arr.copy_to_device(dev_arr)\n",
        "    return t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WBqmq1YfvVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TASK DESCRIPTION:\n",
        "# Find as many as possible articles, that have a indication of bitcoin price going up or down. They are usefull for a Bitcoin trader.\n",
        "# We will randomly select 10 articles from the winner's list for verificaiton and allow not more than 1 incorrectly classified article.\n",
        "# If there is more than 1 incorrectly classified as positive article, we will multiply the score by 0.5 for each cosecutvie incorrectly classified example after the first.\n",
        "# \n",
        "\n",
        "# Recommendations\n",
        "'''\n",
        "Literature:\n",
        "1. https://roywrightme.wordpress.com/2017/11/16/positive-unlabeled-learning/\n",
        "2. http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html\n",
        "\n",
        "1. Firstly, try to clean the positive dataset. You can use free Google Tranlsate API to understand the articles. \n",
        "2. Using the clean dataset, try to train a simple model like logistic regression over glove embeddings and the PU technique\n",
        "3. Using the above model, try to find additional positive articles, that rank high in the above.\n",
        "4. Having additional data, train a more complex model capable of upgrading with Variational Dropout Uncretainty estimation. Recommended example is 1D Convolution. \n",
        "5. By performing na inference on the unlabelled dataset, try to find additional positive sample with low aleatoric uncertainty."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xlXn7mlaksh",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}